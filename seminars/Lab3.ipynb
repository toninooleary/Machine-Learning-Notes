{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar Week 3: Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two streams for this lab session: (i) some Python tutorial covering random number generation, some basic plotting, and matrix operations; (ii) some questions on pre-processing. \n",
    "\n",
    "You should choose yourself which part you want to focus on during the 1 hour class. Part 2 does follow on from the part 1, but some of you might prefer to not have all the details right now, and focus just on using toolboxes to answer the questions in part 2. If you want to write your own code for part 2, then part 1 might be useful.\n",
    "\n",
    "However you approach this lab, you should be generally getting familiar with Python and the toolboxes that are available for doing machine learning.\n",
    "\n",
    "Start by importing the libraries we'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Tutorial: Random number generation, basic plotting, matrix operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random number generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how to generate data that are normally distributed, and plot with a basic histogram. Have a play around with the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 1D data from normal distribution\n",
    "nbpts = 50 # Number of points to generate\n",
    "mu = 1 # the mean\n",
    "sigma = 2 # the standard deviation\n",
    "\n",
    "data = np.random.normal(mu,sigma,(nbpts,1)) # makes a column vector\n",
    "\n",
    "# Create histogram. By default, this will show how many points fall in each bin. \n",
    "bins = 10 # This specifies the number of bins, Python decides the interval. This can be OK but means you do not specify exactly where the bins are. \n",
    "plt.hist(data, bins) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A different specification\n",
    "edges = np.linspace(-5,8,14) # This specifies the number of bins and also where the first bin starts from\n",
    "plt.hist(data, edges)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another specification\n",
    "binsize = 1\n",
    "edges = np.arange(-5,8,binsize) # This specifies a sequence defining the left edge of each bin (and, indirectly, the number of bins) \n",
    "plt.hist(data,edges)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's do a normalised histogram.\n",
    "\n",
    "We are using histograms to estimate probability densities. We need to remember that a probability density function has an area under the curve of 1 (when integrating over all values) so in order to be able to compare histogram and probability density function, we need to normalise our histograms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binsize = 1\n",
    "edges = np.arange(-5,8,binsize) # varying the step size in the sequence means changing the number of bins. Consider what happens when changing the value of binsize\n",
    "plt.hist(data, edges, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can superimpose the pdf (probability density function) of the normal distribution we used to generate the data. We will plot it in the same range as covered by our edges\n",
    "binsize = 1\n",
    "edges = np.arange(-5,8,binsize) # varying the step size in the sequence means changing the number of bins. Consider what happens when changing the value of binsize\n",
    "plt.hist(data, edges, normed=True)\n",
    "x = np.arange(-5,8,0.05) # the x values over which I want the PDF\n",
    "y = stats.norm.pdf(x,mu,sigma)\n",
    "plt.plot(x,y,'r-') # plot with red line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to be clear about is that if you draw data from a distribution, the smaller the number of samples, the less likely you are to be able to accurately estimate the distribution.  A simple example is as follows.  Say I have a biased coin (e.g., a coin that returns heads a bit more often than tails).  I know it’s biased but you don’t.  If I only let you throw it 5 times, how likely are you to be able to infer that it is biased?  What if I let you throw it 100 times?  A million times?  The more you can sample, the more your estimated probability density converges to the true probability density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try generating and plotting some data from another 1-d probability distribution, such as a uniform distribution and/or a log-normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate normal (Gaussian) distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how to generate data from a multivariate normal (Gaussian) distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbpts=100 # number of data points to generate\n",
    "\n",
    "mu=[4,5] # mean of x and mean of y\n",
    "sigma=[1,2] # standard deviation of x and standard deviation of y\n",
    "corr=0.7 # correlation between x and y. This lies between -1 and 1.\n",
    "cov=corr*sigma[0]*sigma[1]  #covariance, which is correlation times the 2 std devs.\n",
    "\n",
    "C=[[sigma[0]**2,cov],[cov,sigma[1]**2]] #  covariance matrix\n",
    "\n",
    "data=np.random.multivariate_normal(mu,C,nbpts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data[:,0],data[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with different ways of visualising 2-d Gaussian data such as that just plotted above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrices are written as lists of rows, and vectors simply as lists. For full functionality, they should be declared as numpy arrays. So for example\n",
    "\n",
    "$A=\\left( \\begin{array}{cc} 2 & 1 \\\\ 4 & 3 \\end{array} \\right)$\n",
    "\n",
    "$B=\\left( \\begin{array}{cc} 5 & 2 \\\\ 2 & 2 \\end{array} \\right)$\n",
    "\n",
    "$v=\\left( \\begin{array}{c} 2 \\\\ 1 \\end{array} \\right)$\n",
    "\n",
    "can be written as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.array([[2,1],[4,3]])\n",
    "B=np.array([[5,2],[2,2]])\n",
    "v=np.array([2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix-vector multiplication and matrix-matrix multiplication are done as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(A,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenvalues and eigenvectors. The following returns an array (not diagonal matrix) of lambda (eigenvalues) and U (eigenvector matrix). The first column corresponds to the first eigenvalue etc.\n",
    "\n",
    "Eigenvectors are normalised to be length 1.\n",
    "\n",
    "(j here is the square root of -1. Eigenvalues and eigenvectors can have complex number entries.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[lambda_arr,U] = linalg.eig(B) # \n",
    "print(lambda_arr)\n",
    "print(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will look into normalisation and PCA. We will be working with two-dimensional\n",
    "data as it is much easier to visualise, however, it is important that any function you write can be generalised\n",
    "to an arbitrary number of dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of these questions, you can consider writing your own code but it's OK if you don't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing package of sklearn:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "A good resource on PCA:\n",
    "\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbpts=100 # number of data points to generate\n",
    "\n",
    "mu=[5,10] # mean of x and mean of y\n",
    "sigma=[1,4] # standard deviation of x and standard deviation of y\n",
    "corr=0.8 # correlation between x and y. This lies between -1 and 1.\n",
    "cov=corr*sigma[0]*sigma[1]  #covariance, which is correlation times the 2 std devs.\n",
    "\n",
    "C=[[sigma[0]**2,cov],[cov,sigma[1]**2]] #  covariance matrix\n",
    "\n",
    "data=np.random.multivariate_normal(mu,C,nbpts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data[:,0],data[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 Simple normalisation\n",
    "\n",
    "Use simple normalisation and plot the original and normalised data on the same\n",
    "graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 PCA\n",
    "\n",
    "Use Principal Component Analysis to reduce the dimension of the data to 1 (i.e. use one principal\n",
    "component). What happens if you use two principal components?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension. Whitening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the whitening method described in the lecture notes and plot the original and whitened data on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
